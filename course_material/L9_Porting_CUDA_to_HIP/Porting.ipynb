{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "916435d8-e663-4bd0-b3e2-8d8344fd6830",
   "metadata": {},
   "source": [
    "# Porting CUDA programs to HIP\n",
    "\n",
    "HIP API calls are designed to closely match their CUDA equivalents. This enables HIP to function as a thin layer over CUDA and allows for reasonably easy porting of CUDA code to HIP code. Often it is just a matter of replacing **cuda -> hip** in the function calls. The ROCM suite provides two different tools **hipify-perl** and **hipify-clang** to help with the porting process. The tool **hipify-perl** is robust and uses perl to perform an intelligent search and replace of cuda calls with hip calls, while the **hipify-clang** tool uses the clang preprocessor to produce a high quality port. The perl-based method is better for quick ports of small codes, while the clang-based method is intended for ports of large codebases. The hipify-clang tool is much more picky though and fails easily unless it has access to all the header files used in the compilation of the CUDA code.\n",
    "\n",
    "## Supported API's\n",
    "\n",
    "The hipify tools will port a majority of CUDA calls as well as calls to CUDA libraries like **cuBLAS**. Tables in [this Github site](https://github.com/ROCm-Developer-Tools/HIPIFY/blob/amd-staging/docs/supported_apis.md) provides some guidance as to what is supported."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aef7d88-273f-4ee5-8a56-a7a4fb64cf2f",
   "metadata": {},
   "source": [
    "## Setup and installation\n",
    "\n",
    "From [this source](https://sep5.readthedocs.io/en/latest/Programming_Guides/HIP-porting-guide.html) it is recommended to attempt porting on a machine that has access to both CUDA and HIP libraries. This usually means doing the port on a machine with an NVIDIA GPU. Then one can try porting portions of the code at a time and compare results. For best results during porting you need to have a version of CUDA that is compatible with your installed version of hipify-clang. The table at [this resource](https://rocm.docs.amd.com/projects/HIPIFY/en/latest/hipify-clang.html) provides information on which version of **hipify-clang** is compatible with which version of CUDA.\n",
    "\n",
    "Once the code is ported and you are running the ported code on AMD hardware it is important to be aware that HIP functions may try to access ROCM libraries on the backend without prior warning of this dependency. It is then a good idea to make sure you have a complete installation of ROCM in addition to having a version of ROCM that is API compatible with your code's version of CUDA. \n",
    "\n",
    "It is also important to be aware that some HIP libraries like **hipBLAS** are built to use the corresponding library from ROCM by default. If you need to use these libaries with a CUDA backend you might need to recompile those libraries for use with CUDA.\n",
    "\n",
    "The code below shows what version of hipify-clang that you are using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "679e253f-cc77-40e8-826d-cc8e904394e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AMD LLVM version 16.0.0git\n",
      "  Optimized build.\n"
     ]
    }
   ],
   "source": [
    "!hipify-clang --version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3341127e-3ad1-45b6-bb3f-0624e4d60c33",
   "metadata": {},
   "source": [
    "Here is a page which describes compatibility between CUDA and your version of hipify-clang. [HIPIFY Documentation](https://rocm.docs.amd.com/projects/HIPIFY/en/latest/hipify-clang.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc7abd4-a72e-468b-b7e6-50bb8a4f6db9",
   "metadata": {},
   "source": [
    "## General porting process\n",
    "\n",
    "The general porting process proceeds as follows:\n",
    "\n",
    "1. Compile with CUDA to verify that the program compiles.\n",
    "1. Run a hipify tool to convert sources.\n",
    "    * Use the flag `-hip-kernel-execution-syntax` to convert CUDA kernel launch syntax to HIP kernel launch syntax.\n",
    "1. Adjust the compilation environment to use **hipcc**.\n",
    "1. Fix compilation errors.\n",
    "    * It can be the most difficult part of porting!\n",
    "    * Use environment variable `HIP_PLATFORM=nvidia` or `HIP_PLATFORM=amd` to switch between backends.\n",
    "    * Preprocessor directives can separate CUDA code from hip-clang code.\n",
    "        * Use the directive `__HIP_PLATFORM_NVIDIA__` for CUDA-specific code.\n",
    "        * Use the directive `__HIP_PLATFORM_AMD__` for separate AMD-specific code.\n",
    "1. Verify code correctness.\n",
    "    * Test on CUDA and AMD architectures to ensure portability\n",
    "1. Re-tune optimisations for new architecture, but only once you know everything works!\n",
    "1. Document the changes made.\n",
    "\n",
    "The step of running the **hipify** tool is the **easiest part** of the process.  If the code uses simple and well-supported CUDA API calls then this has the greatest chance of succeeding. If the codebase contains CUDA-specific complexity, or relies on functionality that is no longer supported by recent version of CUDA, then the level of difficulty in porting can increase **dramatically**. Adjusting the compilation environment for **hipcc** often requires knowledge of  build tools, usually this means a working knowledge of **make** or **cmake**.\n",
    "Familiarity with C++ and what the compiler warnings and errors mean is then crucial to massaging the codebase to accept the new compiler.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d427b5-af01-452e-8bb8-b72c57e47ca7",
   "metadata": {},
   "source": [
    "## Example setup\n",
    "\n",
    "In this example we are going to port a CUDA version of the matrix multiplication code to use HIP. The CUDA version is located in the subdirectory **cuda_mat_mult**, and in the subdirectory **hip_mat_mult** is the corresponding HIP version for reference. On an NVIDIA system you can change directory to **cuda_mat_mult** and run `make` to build the software. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b688398-0021-4023-92e2-1db97cd7084b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -r *.exe\n",
      "nvcc -g -O2 -x cu mat_mult.cpp -o mat_mult.exe -lcuda\n",
      "Device id: 0\n",
      "\tname:                                    NVIDIA GeForce RTX 3060 Laptop GPU\n",
      "\tglobal memory size:                      6226 MB\n",
      "\tavailable registers per block:           65536 \n",
      "\tmaximum shared memory size per block:    49 KB\n",
      "\tmaximum pitch size for memory copies:    2147 MB\n",
      "\tmax block size:                          (1024,1024,64)\n",
      "\tmax threads in a block:                  1024\n",
      "\tmax Grid size:                           (2147483647,65535,65535)\n",
      "Maximum error (infinity norm) is: 1.52588e-05\n"
     ]
    }
   ],
   "source": [
    "!cd cuda_mat_mult; make clean; make; ./mat_mult.exe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbddc62d-858f-4173-8497-f7bc583c9f84",
   "metadata": {},
   "source": [
    "If you list the sources in the directory you can see the C++ file `mat_mult.cpp`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87f25e1c-c118-4724-b469-692290b9059a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array_A.dat  array_C.dat      Makefile\t      mat_mult.cpp  mat_size.hpp\n",
      "array_B.dat  cuda_helper.hpp  mat_helper.hpp  mat_mult.exe\n"
     ]
    }
   ],
   "source": [
    "!ls cuda_mat_mult"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dad6a50-e3ee-4c23-9b9a-1c2440c246cd",
   "metadata": {},
   "source": [
    "Ordinarily CUDA sources would need to end in `.cu` otherwise the `nvcc` compiler won't interpret them as CUDA source files. However since I have specified the `-x cu` flag then `nvcc` treats them as CUDA source. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba935e29-5e67-4abf-a8d0-21f0e14634f3",
   "metadata": {},
   "source": [
    "Let's now make a temporary copy of this directory for conversion purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65ef4517-8bfb-4539-9055-681658dd02a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p temp_mat_mult; cp -r cuda_mat_mult/* temp_mat_mult/ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158aeee9-6c9b-452d-8ab6-510f9d30850f",
   "metadata": {},
   "source": [
    "## Porting techniques with hipify tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fea2199-4187-41fa-8f26-2ef36342b579",
   "metadata": {},
   "source": [
    "### Port a single file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff01866-4aa5-456c-b250-59bb193fb640",
   "metadata": {},
   "source": [
    "The **hipify-perl** command can port a single file to use the HIP API. We use it to port the file **mat_mult.cpp** in the directory **temp_mat_mult**. The flag `-hip-kernel-execution-syntax` changes kernel launch syntax from the CUDA-style triple Chevron `<<< >>>` method to the ANSI C++ compliant method of **hipLaunchKernelGGL**. The following command dumps the output to the command line, but you can use the `-o` flag to specify an output file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9a82eaa-6360-4b8c-8c96-7c121b8fb5f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#include \"hip/hip_runtime.h\"\n",
      "/* Code to perform a Matrix multiplication using cuda\n",
      "Written by Dr Toby M. Potter\n",
      "*/\n",
      "\n",
      "// Setup headers\n",
      "#include <cassert>\n",
      "#include <cmath>\n",
      "#include <iostream>\n",
      "\n",
      "// Bring in the size of the matrices\n",
      "#include \"mat_size.hpp\"\n",
      "\n",
      "// Bring in a library to manage matrices on the CPU\n",
      "#include \"mat_helper.hpp\"\n",
      "\n",
      "// Bring in helper header to manage boilerplate code\n",
      "#include \"cuda_helper.hpp\"\n",
      "\n",
      "// standard matrix multiply kernel \n",
      "__global__ void mat_mult (\n",
      "        float* A, \n",
      "        float* B, \n",
      "        float* C, \n",
      "        size_t N1_A, \n",
      "        size_t N0_C,\n",
      "        size_t N1_C) { \n",
      "            \n",
      "    // A is of size (N0_C, N1_A)\n",
      "    // B is of size (N1_A, N1_C)\n",
      "    // C is of size (N0_C, N1_C)   \n",
      "    \n",
      "    // i0 and i1 represent the coordinates in Matrix C \n",
      "    // We use row-major ordering for the matrices\n",
      "    \n",
      "    size_t i0 = blockIdx.y * blockDim.y + threadIdx.y;\n",
      "    size_t i1 = blockIdx.x * blockDim.x + threadIdx.x;\n",
      "    \n",
      "    // Scratch variable\n",
      "    float temp=0.0f; \n",
      "\n",
      "    // Guard mechanism to make sure we do not go\n",
      "    // outside the boundaries of matrix C \n",
      "    if ((i0<N0_C) && (i1<N1_C)) {\n",
      "        // Get the offset within the memory allocation of C\n",
      "        size_t offset = i0*N1_C+i1;\n",
      "        \n",
      "        // Loop over columns of A and rows of B\n",
      "        for (size_t n=0; n<N1_A; n++) {\n",
      "            \n",
      "            // A is of size (N0_C, N1_A)\n",
      "            // B is of size (N1_A, N1_C)\n",
      "            \n",
      "            // Loop across row i0 of A\n",
      "            // and down column i1 of B\n",
      "            temp+=A[i0*N1_A+n]*B[i1+n*N1_C]; \n",
      "        }\n",
      "        \n",
      "        // Set the value in C at offset\n",
      "        C[offset]=temp;\n",
      "        \n",
      "        // Uncomment this to perform elementwise matrix multiplication instead\n",
      "        // C[offset]=A[offset]*B[offset];\n",
      "    }\n",
      "} \n",
      "\n",
      "int main(int argc, char** argv) {\n",
      "    \n",
      "    //// Step 1. Parse program arguments ////\n",
      "\n",
      "    // Parse command line arguments\n",
      "    int dev_index = h_parse_args(argc, argv);\n",
      "    \n",
      "    // Number of devices discovered\n",
      "    int num_devices=0;\n",
      "    \n",
      "    //// Step 2. Discover resources and choose a compute device ////\n",
      "    \n",
      "    // Helper function to acquire devices\n",
      "    // This sets the default device\n",
      "    h_acquire_devices(&num_devices, dev_index);\n",
      "        \n",
      "    // Report on the device in use\n",
      "    h_report_on_device(dev_index);\n",
      "    \n",
      "    // We are going to do a simple array multiplication for this example, \n",
      "    // using raw binary files for input and output\n",
      "    \n",
      "    // A is of size (N0_C, N1_A)\n",
      "    // B is of size (N1_A, N1_C)    \n",
      "    // C is of size (N0_C, N1_C)\n",
      "\n",
      "    size_t N1_A = NCOLS_A, N0_C = NROWS_C, N1_C = NCOLS_C;\n",
      "\n",
      "    //// Step 3. Construct matrices A_h and B_h on the host \n",
      "    //// and fill them with random numbers ////\n",
      "    \n",
      "    // Number of bytes in each array\n",
      "    size_t nbytes_A = N0_C*N1_A*sizeof(float);\n",
      "    size_t nbytes_B = N1_A*N1_C*sizeof(float);\n",
      "    size_t nbytes_C = N0_C*N1_C*sizeof(float);\n",
      "\n",
      "    // Allocate memory for the host arrays\n",
      "    float* A_h = (float*)h_alloc(nbytes_A);\n",
      "    float* B_h = (float*)h_alloc(nbytes_B);\n",
      "    float* C_h = (float*)h_alloc(nbytes_C);\n",
      "\n",
      "    // Fill the host arrays with random numbers \n",
      "    // using the matrix helper library\n",
      "    m_random(A_h, N0_C, N1_A);\n",
      "    m_random(B_h, N1_A, N1_C);\n",
      "    \n",
      "    //// Step 4. Allocate memory for arrays //// \n",
      "    //// A_d, B_d, and C_d on the compute device ////\n",
      "\n",
      "    float *A_d, *B_d, *C_d;\n",
      "    H_ERRCHK(hipMalloc((void**)&A_d, nbytes_A));\n",
      "    H_ERRCHK(hipMalloc((void**)&B_d, nbytes_B));\n",
      "    H_ERRCHK(hipMalloc((void**)&C_d, nbytes_C));\n",
      "\n",
      "    //// Step 5. 1. Upload matrices A_h and B_h from the host //// \n",
      "    //// to A_d and B_d on the device ////\n",
      "    H_ERRCHK(hipMemcpy(A_d, A_h, nbytes_A, hipMemcpyHostToDevice));\n",
      "    H_ERRCHK(hipMemcpy(B_d, B_h, nbytes_B, hipMemcpyHostToDevice));\n",
      " \n",
      "    //// Step 6. Run the kernel to compute C_d ///\n",
      "    //// from A_d and B_d on the device ////\n",
      "        \n",
      "    // Desired block size\n",
      "    dim3 block_size = { 8, 8, 1 };\n",
      "    dim3 global_size = { (uint32_t)N1_C, (uint32_t)N0_C, 1 };\n",
      "    dim3 grid_nblocks;\n",
      "    \n",
      "    // Choose the number of blocks so that Grid fits within it.\n",
      "    h_fit_blocks(&grid_nblocks, global_size, block_size);\n",
      "\n",
      "    // Amount of shared memory to use in the kernel\n",
      "    size_t sharedMemBytes=0;\n",
      "    \n",
      "    // Launch the kernel using CUDA triple Chevron syntax\n",
      "    // Use 0 when choosing the default (null) stream\n",
      "    hipLaunchKernelGGL(mat_mult, grid_nblocks, block_size, sharedMemBytes, 0, A_d, B_d, C_d, N1_A, N0_C, N1_C);\n",
      "    \n",
      "    // Check the status of the kernel launch\n",
      "    H_ERRCHK(hipGetLastError());\n",
      "    \n",
      "    // Wait for any commands to complete on the compute device\n",
      "    H_ERRCHK(hipDeviceSynchronize());\n",
      "\n",
      "    //// Step 7. Copy the buffer for matrix C_d //// \n",
      "    //// on the device back to C_h on the host ////\n",
      "    H_ERRCHK(hipMemcpy((void*)C_h, (const void*)C_d, nbytes_C, hipMemcpyDeviceToHost));\n",
      "    \n",
      "    //// Step 8. Test the computed matrix **C_h** against a known answer\n",
      "    \n",
      "    // Compute the serial solution using the matrix helper library\n",
      "    float* C_answer_h = (float*)calloc(nbytes_C, 1);\n",
      "    m_mat_mult(A_h, B_h, C_answer_h, N1_A, N0_C, N1_C);\n",
      "    \n",
      "    // Uncomment this to check against elementwise matrix multiplication\n",
      "    // m_hadamard(A_h, B_h, C_answer_h, N0_C, N1_C);\n",
      "\n",
      "    // Print the maximum error between matrices\n",
      "    float max_err = m_max_error(C_h, C_answer_h, N0_C, N1_C);\n",
      "    \n",
      "    //// Step 9. Write the contents of matrices A_h, B_h, and C_h to disk ////\n",
      "\n",
      "    // Write out the host arrays to file\n",
      "    h_write_binary(A_h, \"array_A.dat\", nbytes_A);\n",
      "    h_write_binary(B_h, \"array_B.dat\", nbytes_B);\n",
      "    h_write_binary(C_h, \"array_C.dat\", nbytes_C);\n",
      "    \n",
      "    //// Step 10. Clean up memory alllocations and release resources\n",
      "    \n",
      "    // Free the cuda buffers\n",
      "    H_ERRCHK(hipFree(A_d));\n",
      "    H_ERRCHK(hipFree(B_d));\n",
      "    H_ERRCHK(hipFree(C_d));\n",
      "\n",
      "    // Clean up host memory\n",
      "    free(A_h);\n",
      "    free(B_h);\n",
      "    free(C_h);\n",
      "\n",
      "    // Free the answer matrix\n",
      "    free(C_answer_h);\n",
      "    \n",
      "    // Reset compute devices\n",
      "    h_reset_devices(num_devices);\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!cd temp_mat_mult; hipify-perl -hip-kernel-execution-syntax mat_mult.cpp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747905a4-2e43-4269-900f-de3bd4205f5f",
   "metadata": {},
   "source": [
    "If we use the `-inplace` flag, **hipify-perl** copies the file [mat_mult.cpp](temp_mat_mult/mat_mult.cpp) first to [mat_mult.cpp.prehip](temp_mat_mult/mat_mult.cpp.prehip) **if that file doesn't already exist**. Then it performs the conversion from [mat_mult.cpp.prehip](temp_mat_mult/mat_mult.cpp.prehip) to [mat_mult.cpp](temp_mat_mult/mat_mult.cpp). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4704d730-6ab7-4216-89d9-6b13eeb0024e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[HIPIFY] info: file 'mat_mult.cpp' statistics:\n",
      "  CONVERTED refs count: 15\n",
      "  TOTAL lines of code: 190\n",
      "  WARNINGS: 0\n",
      "[HIPIFY] info: CONVERTED refs by names:\n",
      "  cudaDeviceSynchronize => hipDeviceSynchronize: 1\n",
      "  cudaFree => hipFree: 3\n",
      "  cudaGetLastError => hipGetLastError: 1\n",
      "  cudaMalloc => hipMalloc: 3\n",
      "  cudaMemcpy => hipMemcpy: 3\n",
      "  cudaMemcpyDeviceToHost => hipMemcpyDeviceToHost: 1\n",
      "  cudaMemcpyHostToDevice => hipMemcpyHostToDevice: 2\n"
     ]
    }
   ],
   "source": [
    "!cd temp_mat_mult; hipify-perl -inplace -print-stats -hip-kernel-execution-syntax mat_mult.cpp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498f4116-e38e-4113-a148-844a92d8b83a",
   "metadata": {},
   "source": [
    "Subsequent edits to [mat_mult.cpp.prehip](temp_mat_mult/mat_mult.cpp.prehip) will be propagated across to [mat_mult.cpp](temp_mat_mult/mat_mult.cpp). This allows for an iterative porting process. Use the `--help` flag for more porting options."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f4a7d3-8c4d-431b-901a-870916d81a58",
   "metadata": {},
   "source": [
    "### Examine a directory structure for porting potential\n",
    "\n",
    "We use the scripts **hipexamine-perl.sh** or **hipexamine.sh** to recursively search through a directory and examine the potential for porting a code. Note there is a summary produced for each file, showing what API calls were converted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12620b08-509c-4d8b-ae80-8534892a134b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[HIPIFY] info: file 'cuda_mat_mult/mat_mult.cpp' statistics:\n",
      "  CONVERTED refs count: 14\n",
      "  TOTAL lines of code: 190\n",
      "  WARNINGS: 0\n",
      "[HIPIFY] info: CONVERTED refs by names:\n",
      "  cudaDeviceSynchronize => hipDeviceSynchronize: 1\n",
      "  cudaFree => hipFree: 3\n",
      "  cudaGetLastError => hipGetLastError: 1\n",
      "  cudaMalloc => hipMalloc: 3\n",
      "  cudaMemcpy => hipMemcpy: 3\n",
      "  cudaMemcpyDeviceToHost => hipMemcpyDeviceToHost: 1\n",
      "  cudaMemcpyHostToDevice => hipMemcpyHostToDevice: 2\n",
      "  warning: cuda_mat_mult/cuda_helper.hpp:480: removed identifier \"cudaLaunch\" since CUDA 10.1\n",
      "\n",
      "[HIPIFY] info: file 'cuda_mat_mult/cuda_helper.hpp' statistics:\n",
      "  CONVERTED refs count: 55\n",
      "  TOTAL lines of code: 789\n",
      "  WARNINGS: 1\n",
      "[HIPIFY] info: CONVERTED refs by names:\n",
      "  CUDA_SUCCESS => hipSuccess: 4\n",
      "  CUresult => hipError_t: 4\n",
      "  cuGetErrorString => hipDrvGetErrorString: 1\n",
      "  cuInit => hipInit: 1\n",
      "  cuda.h => hip/hip_runtime.h: 2\n",
      "  cudaDevAttrManagedMemory => hipDeviceAttributeManagedMemory: 1\n",
      "  cudaDeviceGetAttribute => hipDeviceGetAttribute: 1\n",
      "  cudaDeviceProp => hipDeviceProp_t: 2\n",
      "  cudaDeviceReset => hipDeviceReset: 1\n",
      "  cudaDeviceSynchronize => hipDeviceSynchronize: 1\n",
      "  cudaError_t => hipError_t: 4\n",
      "  cudaEventCreate => hipEventCreate: 2\n",
      "  cudaEventDestroy => hipEventDestroy: 2\n",
      "  cudaEventElapsedTime => hipEventElapsedTime: 1\n",
      "  cudaEventRecord => hipEventRecord: 3\n",
      "  cudaEventSynchronize => hipEventSynchronize: 2\n",
      "  cudaEvent_t => hipEvent_t: 3\n",
      "  cudaGetDevice => hipGetDevice: 1\n",
      "  cudaGetDeviceCount => hipGetDeviceCount: 2\n",
      "  cudaGetDeviceProperties => hipGetDeviceProperties: 2\n",
      "  cudaGetErrorString => hipGetErrorString: 2\n",
      "  cudaLaunchKernel => hipLaunchKernel: 1\n",
      "  cudaSetDevice => hipSetDevice: 3\n",
      "  cudaStreamCreateWithFlags => hipStreamCreateWithFlags: 1\n",
      "  cudaStreamDefault => hipStreamDefault: 1\n",
      "  cudaStreamDestroy => hipStreamDestroy: 1\n",
      "  cudaStreamNonBlocking => hipStreamNonBlocking: 1\n",
      "  cudaStream_t => hipStream_t: 7\n",
      "  cudaSuccess => hipSuccess: 4\n",
      "  cuda_runtime.h => hip/hip_runtime.h: 2\n",
      "\n",
      "[HIPIFY] info: file 'GLOBAL' statistics:\n",
      "  CONVERTED refs count: 69\n",
      "  TOTAL lines of code: 1162\n",
      "  WARNINGS: 1\n",
      "[HIPIFY] info: CONVERTED refs by names:\n",
      "  CUDA_SUCCESS => hipSuccess: 4\n",
      "  CUresult => hipError_t: 4\n",
      "  cuGetErrorString => hipDrvGetErrorString: 1\n",
      "  cuInit => hipInit: 1\n",
      "  cuda.h => hip/hip_runtime.h: 2\n",
      "  cudaDevAttrManagedMemory => hipDeviceAttributeManagedMemory: 1\n",
      "  cudaDeviceGetAttribute => hipDeviceGetAttribute: 1\n",
      "  cudaDeviceProp => hipDeviceProp_t: 2\n",
      "  cudaDeviceReset => hipDeviceReset: 1\n",
      "  cudaDeviceSynchronize => hipDeviceSynchronize: 2\n",
      "  cudaError_t => hipError_t: 4\n",
      "  cudaEventCreate => hipEventCreate: 2\n",
      "  cudaEventDestroy => hipEventDestroy: 2\n",
      "  cudaEventElapsedTime => hipEventElapsedTime: 1\n",
      "  cudaEventRecord => hipEventRecord: 3\n",
      "  cudaEventSynchronize => hipEventSynchronize: 2\n",
      "  cudaEvent_t => hipEvent_t: 3\n",
      "  cudaFree => hipFree: 3\n",
      "  cudaGetDevice => hipGetDevice: 1\n",
      "  cudaGetDeviceCount => hipGetDeviceCount: 2\n",
      "  cudaGetDeviceProperties => hipGetDeviceProperties: 2\n",
      "  cudaGetErrorString => hipGetErrorString: 2\n",
      "  cudaGetLastError => hipGetLastError: 1\n",
      "  cudaLaunchKernel => hipLaunchKernel: 1\n",
      "  cudaMalloc => hipMalloc: 3\n",
      "  cudaMemcpy => hipMemcpy: 3\n",
      "  cudaMemcpyDeviceToHost => hipMemcpyDeviceToHost: 1\n",
      "  cudaMemcpyHostToDevice => hipMemcpyHostToDevice: 2\n",
      "  cudaSetDevice => hipSetDevice: 3\n",
      "  cudaStreamCreateWithFlags => hipStreamCreateWithFlags: 1\n",
      "  cudaStreamDefault => hipStreamDefault: 1\n",
      "  cudaStreamDestroy => hipStreamDestroy: 1\n",
      "  cudaStreamNonBlocking => hipStreamNonBlocking: 1\n",
      "  cudaStream_t => hipStream_t: 7\n",
      "  cudaSuccess => hipSuccess: 4\n",
      "  cuda_runtime.h => hip/hip_runtime.h: 2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!hipexamine-perl.sh cuda_mat_mult -exclude-dirs=\".ipynb_checkpoints\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3117e3-f3bf-4c7f-9351-085154143a0e",
   "metadata": {},
   "source": [
    "If we try the hip-clang version we see that it doesn't handle preprocessor directives very well. The following errors with `_aligned_malloc` are due to it not picking up the windows-specific `#define` clauses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a5ac422-ce12-4499-9aed-93f4db9559bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[HIPIFY] error: hipify-clang: Unknown command line argument '-exclude-dirs=.ipynb_checkpoints'.  Try: '/opt/rocm-5.6.1/bin/hipify-clang --help'\n",
      "hipify-clang: Did you mean '--o-dir=.ipynb_checkpoints'?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!hipexamine.sh ./cuda_mat_mult -exclude-dirs=\".ipynb_checkpoints\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec657b6f-2a15-4ad1-b8ef-650aedeb25fb",
   "metadata": {},
   "source": [
    "### Porting a directory structure inplace\n",
    "\n",
    "Both the **hipconvertinplace-perl.sh** and **hipconvertinplace.sh** scripts have the ability to convert a code tree inplace. The additional option **-hip-kernel-execution-syntax** replaces CUDA triple Chevron kernel calls with the equivalent call to **hipLaunchKernelGGL** macro.\n",
    "\n",
    "#### Porting inplace with hipify-perl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23846221-b541-45a8-950b-9278b477b207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[HIPIFY] info: file 'temp_mat_mult/mat_mult.cpp' statistics:\n",
      "  CONVERTED refs count: 15\n",
      "  TOTAL lines of code: 190\n",
      "  WARNINGS: 0\n",
      "[HIPIFY] info: CONVERTED refs by names:\n",
      "  cudaDeviceSynchronize => hipDeviceSynchronize: 1\n",
      "  cudaFree => hipFree: 3\n",
      "  cudaGetLastError => hipGetLastError: 1\n",
      "  cudaMalloc => hipMalloc: 3\n",
      "  cudaMemcpy => hipMemcpy: 3\n",
      "  cudaMemcpyDeviceToHost => hipMemcpyDeviceToHost: 1\n",
      "  cudaMemcpyHostToDevice => hipMemcpyHostToDevice: 2\n",
      "  warning: temp_mat_mult/cuda_helper.hpp:480: removed identifier \"cudaLaunch\" since CUDA 10.1\n",
      "\n",
      "[HIPIFY] info: file 'temp_mat_mult/cuda_helper.hpp' statistics:\n",
      "  CONVERTED refs count: 56\n",
      "  TOTAL lines of code: 789\n",
      "  WARNINGS: 1\n",
      "[HIPIFY] info: CONVERTED refs by names:\n",
      "  CUDA_SUCCESS => hipSuccess: 4\n",
      "  CUresult => hipError_t: 4\n",
      "  cuGetErrorString => hipDrvGetErrorString: 1\n",
      "  cuInit => hipInit: 1\n",
      "  cuda.h => hip/hip_runtime.h: 2\n",
      "  cudaDevAttrManagedMemory => hipDeviceAttributeManagedMemory: 1\n",
      "  cudaDeviceGetAttribute => hipDeviceGetAttribute: 1\n",
      "  cudaDeviceProp => hipDeviceProp_t: 2\n",
      "  cudaDeviceReset => hipDeviceReset: 1\n",
      "  cudaDeviceSynchronize => hipDeviceSynchronize: 1\n",
      "  cudaError_t => hipError_t: 4\n",
      "  cudaEventCreate => hipEventCreate: 2\n",
      "  cudaEventDestroy => hipEventDestroy: 2\n",
      "  cudaEventElapsedTime => hipEventElapsedTime: 1\n",
      "  cudaEventRecord => hipEventRecord: 3\n",
      "  cudaEventSynchronize => hipEventSynchronize: 2\n",
      "  cudaEvent_t => hipEvent_t: 3\n",
      "  cudaGetDevice => hipGetDevice: 1\n",
      "  cudaGetDeviceCount => hipGetDeviceCount: 2\n",
      "  cudaGetDeviceProperties => hipGetDeviceProperties: 2\n",
      "  cudaGetErrorString => hipGetErrorString: 2\n",
      "  cudaLaunchKernel => hipLaunchKernel: 1\n",
      "  cudaSetDevice => hipSetDevice: 3\n",
      "  cudaStreamCreateWithFlags => hipStreamCreateWithFlags: 1\n",
      "  cudaStreamDefault => hipStreamDefault: 1\n",
      "  cudaStreamDestroy => hipStreamDestroy: 1\n",
      "  cudaStreamNonBlocking => hipStreamNonBlocking: 1\n",
      "  cudaStream_t => hipStream_t: 7\n",
      "  cudaSuccess => hipSuccess: 4\n",
      "  cuda_runtime.h => hip/hip_runtime.h: 2\n",
      "\n",
      "[HIPIFY] info: file 'GLOBAL' statistics:\n",
      "  CONVERTED refs count: 71\n",
      "  TOTAL lines of code: 1162\n",
      "  WARNINGS: 1\n",
      "[HIPIFY] info: CONVERTED refs by names:\n",
      "  CUDA_SUCCESS => hipSuccess: 4\n",
      "  CUresult => hipError_t: 4\n",
      "  cuGetErrorString => hipDrvGetErrorString: 1\n",
      "  cuInit => hipInit: 1\n",
      "  cuda.h => hip/hip_runtime.h: 2\n",
      "  cudaDevAttrManagedMemory => hipDeviceAttributeManagedMemory: 1\n",
      "  cudaDeviceGetAttribute => hipDeviceGetAttribute: 1\n",
      "  cudaDeviceProp => hipDeviceProp_t: 2\n",
      "  cudaDeviceReset => hipDeviceReset: 1\n",
      "  cudaDeviceSynchronize => hipDeviceSynchronize: 2\n",
      "  cudaError_t => hipError_t: 4\n",
      "  cudaEventCreate => hipEventCreate: 2\n",
      "  cudaEventDestroy => hipEventDestroy: 2\n",
      "  cudaEventElapsedTime => hipEventElapsedTime: 1\n",
      "  cudaEventRecord => hipEventRecord: 3\n",
      "  cudaEventSynchronize => hipEventSynchronize: 2\n",
      "  cudaEvent_t => hipEvent_t: 3\n",
      "  cudaFree => hipFree: 3\n",
      "  cudaGetDevice => hipGetDevice: 1\n",
      "  cudaGetDeviceCount => hipGetDeviceCount: 2\n",
      "  cudaGetDeviceProperties => hipGetDeviceProperties: 2\n",
      "  cudaGetErrorString => hipGetErrorString: 2\n",
      "  cudaGetLastError => hipGetLastError: 1\n",
      "  cudaLaunchKernel => hipLaunchKernel: 1\n",
      "  cudaMalloc => hipMalloc: 3\n",
      "  cudaMemcpy => hipMemcpy: 3\n",
      "  cudaMemcpyDeviceToHost => hipMemcpyDeviceToHost: 1\n",
      "  cudaMemcpyHostToDevice => hipMemcpyHostToDevice: 2\n",
      "  cudaSetDevice => hipSetDevice: 3\n",
      "  cudaStreamCreateWithFlags => hipStreamCreateWithFlags: 1\n",
      "  cudaStreamDefault => hipStreamDefault: 1\n",
      "  cudaStreamDestroy => hipStreamDestroy: 1\n",
      "  cudaStreamNonBlocking => hipStreamNonBlocking: 1\n",
      "  cudaStream_t => hipStream_t: 7\n",
      "  cudaSuccess => hipSuccess: 4\n",
      "  cuda_runtime.h => hip/hip_runtime.h: 2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!hipconvertinplace-perl.sh temp_mat_mult -hip-kernel-execution-syntax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2326375-a616-4704-81c3-9c3c671151bb",
   "metadata": {},
   "source": [
    "#### Porting inplace with hipify-clang\n",
    "\n",
    "Here is the same port with **hipify-clang**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3be9bcbc-4135-41ab-903d-c048cabbf961",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!hipconvertinplace.sh temp_mat_mult -hip-kernel-execution-syntax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc505b5e-1291-4007-86e8-ae027dfca4cd",
   "metadata": {},
   "source": [
    "### Building the ported code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f3bf73-e76a-49cc-b006-4b90e1eed6b2",
   "metadata": {},
   "source": [
    "If we examine the source tree we see that every source file that has been hipified has been first copied to a file with suffix `*.prehip`. Then the converted code is overwritten in place of the old file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "93c79b1c-e721-4421-9183-a44ed01ccedd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 2380\n",
      "-rw-rw-r-- 1 toby toby  262144 Sep 28 14:20 array_A.dat\n",
      "-rw-rw-r-- 1 toby toby  262144 Sep 28 14:20 array_B.dat\n",
      "-rw-rw-r-- 1 toby toby  262144 Sep 28 14:20 array_C.dat\n",
      "-rw-rw-r-- 1 toby toby   24660 Sep 28 14:21 cuda_helper.hpp\n",
      "-rw-rw-r-- 1 toby toby   24629 Sep 28 14:21 cuda_helper.hpp.prehip\n",
      "-rw-rw-r-- 1 toby toby     341 Sep 28 14:20 Makefile\n",
      "-rw-rw-r-- 1 toby toby    4497 Sep 28 14:21 mat_helper.hpp\n",
      "-rw-rw-r-- 1 toby toby    4497 Sep 28 14:21 mat_helper.hpp.prehip\n",
      "-rw-rw-r-- 1 toby toby    5975 Sep 28 14:21 mat_mult.cpp\n",
      "-rw-rw-r-- 1 toby toby    5944 Sep 28 14:21 mat_mult.cpp.prehip\n",
      "-rwxrwxr-x 1 toby toby 1545520 Sep 28 14:20 mat_mult.exe\n",
      "-rw-rw-r-- 1 toby toby     107 Sep 28 14:21 mat_size.hpp\n",
      "-rw-rw-r-- 1 toby toby     107 Sep 28 14:21 mat_size.hpp.prehip\n"
     ]
    }
   ],
   "source": [
    "!ls -l temp_mat_mult"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2964cedf-53df-49d3-a98a-812a59e34aeb",
   "metadata": {},
   "source": [
    "Try making the ported code with hipcc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1e07138-163e-4615-93fe-62b653908f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -r *.exe\n",
      "hipcc -g -O2 -x cu mat_mult.cpp -o mat_mult.exe \n",
      "\u001b[01m\u001b[0m\u001b[01mcuda_helper.hpp(54)\u001b[0m: \u001b[01;31merror\u001b[0m: function \u001b[01m\"h_errchk\"\u001b[0m has already been defined\n",
      "  void h_errchk(hipError_t errcode, const char* message) {\n",
      "       ^\n",
      "\n",
      "1 error detected in the compilation of \"mat_mult.cpp\".\n",
      "make: *** [Makefile:16: mat_mult.exe] Error 2\n"
     ]
    }
   ],
   "source": [
    "!cd temp_mat_mult; make clean; make CXX=\"hipcc\" LIBFLAGS=\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39501460-ca62-4103-be05-aa00069beaaf",
   "metadata": {},
   "source": [
    "In the original file **cuda_mat_mult/cuda_helper.cpp** we had overloaded the **h_errchk** function to accept errorcodes of both type **CUResult** and **cudaError_t**. Following conversion to HIP the errorcode has been replaced with just **hipError_t**. Therefore we need to manually delete the duplicate **h_errchk** function in **[temp_mat_mult/cuda_helper.hpp.prehip](temp_mat_mult/cuda_helper.hpp.prehip)**. Then rerun the conversion and the make. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9142234b-e1d6-4a1c-b387-c679b25df42b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  warning: cuda_helper.hpp:451: removed identifier \"cudaLaunch\" since CUDA 10.1\n",
      "make: Nothing to be done for 'all'.\n",
      "Device id: 0\n",
      "\tname:                                    NVIDIA GeForce RTX 3060 Laptop GPU\n",
      "\tglobal memory size:                      6226 MB\n",
      "\tavailable registers per block:           65536 \n",
      "\tmaximum shared memory size per block:    49 KB\n",
      "\tmaximum pitch size for memory copies:    2147 MB\n",
      "\tmax block size:                          (1024,1024,64)\n",
      "\tmax threads in a block:                  1024\n",
      "\tmax Grid size:                           (2147483647,65535,65535)\n",
      "Maximum error (infinity norm) is: 1.52588e-05\n"
     ]
    }
   ],
   "source": [
    "!cd temp_mat_mult; hipify-perl -inplace -hip-kernel-execution-syntax cuda_helper.hpp\n",
    "!cd temp_mat_mult; make CXX=\"hipcc\" LIBFLAGS=\"\"; ./mat_mult.exe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218d61e3-fdc4-4dd1-8ac1-e537872577fb",
   "metadata": {},
   "source": [
    "Now we should have a successful port of the CUDA code to HIP!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7773754-7ae2-47e9-b51a-bf220e64241f",
   "metadata": {},
   "source": [
    "## Case studies in porting codes\n",
    "\n",
    "Apart from the toy example above it is informative to try porting some real-world applications and see what learnings can be derived from the process. Here are a few dot points that stood out from. \n",
    "\n",
    "### Visualising shipwrecks\n",
    "\n",
    "From [this resource](https://blogs.nvidia.com/blog/2022/11/18/3d-shipwrecks-perth/) researchers at Curtin University are using open source visualisation software to render 3D environments of shipwrecks. Some feedback from their work was:\n",
    "\n",
    "* Fragility between CUDA and HIP API's. One had to have a version of ROCM that closely matches the CUDA library.\n",
    "* Some CUDA functions were just wrappers that call other CUDA functions and thus were unable to be ported.\n",
    "* HIP functions would call ROCM functions on an AMD backend. It was a trial and error process to work out what ROCM libraries were requried.\n",
    "\n",
    "### FiCoS\n",
    "\n",
    "From [this github site](https://gitlab.com/andrea-tango/ficos) FiCoS is a simulator for biochemical networks. It uses CUDA to solve Ordinary Differential Equations (ODE's) in parallel over a GPU. As the project is quite small the **hipconvertinplace-perl.sh** script was used to easily port the code. During compilation I encountered numerous errors of the following type:\n",
    "\n",
    "* Arrays of the data type **hipDoubleComplex** was incompatible with required input arguments **hipBlasDoubleComplex** for hibBlas routines  when trying to use the NVIDIA backend. This was not an issue with the AMD backend.\n",
    "* Dynamic parallelism (kernels launching kernels) is a design feature that is employed in this code. Dynamic parallelism is not supported on the AMD backend, which means that the codebase must be refactored in order to use AMD.\n",
    "\n",
    "### CURC\n",
    "\n",
    "[CURC](https://github.com/BioinfoSZU/CURC) is a CUDA-based bioinformatics tool to compress and decompress genome information from FASTQ files. \n",
    "\n",
    "* The port itself proceeded smoothly, however there were a lot of warnings about texture reference API calls, which are not supported in HIP and no longer supported in CUDA 12 in favour of texture object API calls.\n",
    "* Cmake build system was CUDA-specific and required modification to use HIP.\n",
    "\n",
    "### Miluphcuda\n",
    "\n",
    "From their [Github page](https://github.com/christophmschaefer/miluphcuda) Miluphcuda is a CUDA-based Smoothed Particle Hydrodynamics code for modelling astrophysical impacts. Porting this source tree was a **complete success** as it did not use any deprecated or CUDA-specific features, and required only minor syntactical changes. One flag that was required during compilation was `-fgpu-rc`, and that is because some source files relied on constant memory whose symbols were uploaded in another source file. The relocatable device flag enabled compiliation to be okay with the absent symbols. The ported source tree is available [here](https://github.com/drtpotter/miluph-hip)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2d5ccc-66a6-4dff-a76e-2b017591f613",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Learnings from the porting process\n",
    "\n",
    "### Code complexity can be an enemy of progress!\n",
    "\n",
    "The quest for greater performance often comes at the price of greater complexity. Porting efforts in the case studies were often thwarted because I would encounter assembly code or esoteric CUDA features like texture reference calls that are no longer supported by CUDA or HIP. When developing codes it is important to weigh in tradeoffs between small increases in efficiency versus the developer cost of maintaining this complexity.\n",
    "\n",
    "### Hardware differences between GPU's\n",
    "\n",
    "#### Thread team size\n",
    "\n",
    "From [Yuhsiang et al (2020)](https://www.researchgate.net/publication/342464640_Preparing_Ginkgo_for_AMD_GPUs_--_A_Testimonial_on_Porting_CUDA_Code_to_HIP) the primary architectural difference between AMD and NVIDIA is AMD's use of 64 threads in a thread team versus 32 threads for NVIDIA devices.\n",
    "\n",
    "#### Available registers at peak occupancy\n",
    "\n",
    "We saw from Lesson 7 that the MI250X GPU may have fewer available registers per kernel thread in order to maintain peak occupancy. Combined with difference in compiler and runtime maturity, this may mean that a kernel running on AMD hardware may not achieve the same occupancy as it did on NVIDIA hardware. The tool Omniperf is good at showing the occupancy of your kernels. If you see reduced occupancy in ported code then see some of the tips in Lesson 7 on <a href=\"../L7_Kernel_Optimisation/Optimisation.ipynb\">optimising kernels</a> to try and reduce register pressure.\n",
    "\n",
    "### Software differences between CUDA and hip-clang\n",
    "\n",
    "CUDA has the notion of a driver API and a runtime API. HIP combines the two into one API and then supports a subset of the combined API. This [table](https://rocm.docs.amd.com/projects/HIP/en/latest/user_guide/faq.html#what-apis-and-features-does-hip-support) has the most up-to-date listing of features that are supported and not supported in HIP. In particular, here are some notable points of difference between CUDA and HIP.\n",
    "\n",
    "* Launching kernels from kernels (dynamic parallelism) is not supported in HIP. Avoid using this design pattern when building cross-platform code.\n",
    "* Context management is deprecated in HIP. CUDA code that uses contexts can be migrated to HIP's simpler method of using primary contexts and switching devices from threads.\n",
    "* Graphics interopability with OpenGL is not yet supported.\n",
    "* The CUDA API has undergone some major changes such as the removal (since CUDA 12) of the texture reference API in favour of the texture object API.\n",
    "* Any inline PTX assembly instructions for CUDA kernels will need to be ported across to AMD kernels. Use the preprocessor directives `__HIP_PLATFORM_NVIDIA__` and `__HIP_PLATFORM_AMD__` to enclose vendor specific code.\n",
    "* CUDA doesn't appear to support math operations on vector types. Use preprocessor directives to index into individual vector components when using the CUDA backend.\n",
    "\n",
    "## Miscellaneous tips\n",
    "\n",
    "### Relocatable device code\n",
    "\n",
    "From [this source](https://docs.amd.com/projects/HIP/en/latest/user_guide/hip_porting_driver_api.html) The linker option `-fgpu-rdc` allows for kernels to call functions that are compiled for different translation units. This is useful for instances where a kernel might not be aware of things like allocations in constant memory where symbols are uploaded in another file. At the [Pawsey P'Con 23 Hackathon](https://pawsey.org.au/event/pacer-conference-2023-pcon23-registration/) a team found that the use of this flag generated excessively long link times though. \n",
    "\n",
    "### Preprocessor directives\n",
    "\n",
    "During compilation the preprocessor directive `__HIP_PLATFORM_NVIDIA__` is defined when using an NVIDIA backend, and the preprocessor directive `__HIP_PLATFORM_AMD__` is defined when using an AMD backend.\n",
    "\n",
    "### Switching between backends\n",
    "\n",
    "The environment variable `HIP_PLATFORM` controls what backend to use when compiling HIP source. Set `HIP_PLATFORM=nvidia` to use the CUDA backend and set `HIP_PLATFORM=amd` or leave it unset to use the AMD backend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f889c4ac-b68a-48ca-9914-6d3aac36e9af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
