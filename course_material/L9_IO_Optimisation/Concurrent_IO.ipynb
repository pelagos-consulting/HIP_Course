{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49390830-5c18-41f4-9f1d-18bddc857edd",
   "metadata": {},
   "source": [
    "# Optimising compute with concurrent IO in OpenCL\n",
    "\n",
    "With many iterative processes there is a need to get information **off** the device at regular intervals. Up to this point we have been transferring data off the compute device **after** kernel execution. Also, the routines to read information from device buffers have thus far been used in a blocking manner, that is the program pauses while the read occurs. Most compute devices have the ability to transfer data **while** kernels are being executed. This means IO transfers can take place during compute and may in some instances **take place entirely** during kernel execution. For the cost of additional programming complexity, significant compute savings can be obtained, as the following diagram illustrates:\n",
    "\n",
    "<figure style=\"margin-bottom 3em; margin-top: 2em; margin-left:auto; margin-right:auto; width:100%\">\n",
    "    <img style=\"vertical-align:middle\" src=\"../images/optimising_io.svg\"> <figcaption style= \"text-align:lower; margin:1em; float:bottom; vertical-align:bottom;\">Figure: The difference between sequential and concurrent IO.</figcaption>\n",
    "</figure>\n",
    "\n",
    "## Concurrent IO is enabled with multiple command queues\n",
    "\n",
    "The **key to leveraging concurrent IO** is to have one command queue for the kernels and one or more command queues for moving data. Then IO operations can take place largely independently of the compute operations. OpenCL Events and the [clFinish](https://registry.khronos.org/OpenCL/sdk/3.0/docs/man/html/clFinish.html) command can help establish dependencies between command queues. Non-blocking IO calls may also help with concurrency."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec04ce78-df29-42dd-a38a-822a23407cae",
   "metadata": {},
   "source": [
    "## Example with the 2D wave equation\n",
    "\n",
    "The [scalar wave equation](https://en.wikipedia.org/wiki/Wave_equation) adequately describes a number of different wave phenomena. If **U** is a 2D grid storing the amplitude of the wave at every location (the wavefield), **V** is a 2D grid storing velocity, and **t** is time, then 2D waves propagate according to the formula,\n",
    "\n",
    "$$\\frac{\\partial^2 \\textbf{U}}{{\\partial t}^2}=\\textbf{V}^2 \\left (\\frac{\\partial^2 \\textbf{U}}{{\\partial x_{0}}^2}+\\frac{\\partial^2 \\textbf{U}}{{\\partial x_{1}}^2} \\right)+f(t)$$\n",
    "\n",
    "where $x_0$ and $x_1$ are spatial directions and $f(t)$ is a forcing term. If $\\Delta t$ is the time step a second-order finite-difference approximation to the time derivative is given in terms of the amplitude at timesteps $\\textbf{U}_{0}, \\textbf{U}_{1}$ and $\\textbf{U}_{2}.$ \n",
    "\n",
    "$$\\frac{\\partial^2 \\textbf{U}}{{\\partial t}^2} \\approx \\frac{1}{\\Delta t^2} \\left ( \\textbf{U}_{0} -2 \\textbf{U}_{1}+\\textbf{U}_{2} \\right ) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78810535-577b-4789-a36c-d5a43d759bd7",
   "metadata": {},
   "source": [
    "Replace $\\frac{\\partial^2 \\textbf{U}}{{\\partial t}^2}$ with $\\frac{1}{\\Delta t^2} \\left( \\textbf{U}_{0} -2 \\textbf{U}_{1}+\\textbf{U}_{2} \\right )$ and solve for $\\textbf{U}_{2}$.\n",
    "\n",
    "$$\\textbf{U}_{2} \\approx 2 \\textbf{U}_{1} - \\textbf{U}_{0} + \\Delta t^2\\textbf{V}^2 \\left (\\frac{\\partial^2 \\textbf{U}_{1}}{{\\partial x_{0}}^2}+\\frac{\\partial^2 \\textbf{U}_{1}}{{\\partial x_{1}}^2} \\right)+f_{1}$$\n",
    "\n",
    "This is an iterative formula to generate the amplitude at the next timestep $\\textbf{U}_2$ if we know the present ampltiude $\\textbf{U}_{1}$ and past amplitude $\\textbf{U}_{0}.$ We also use finite difference approximations for the spatial derivatives, and express the spatial derivatives as a matrix multiplied by $\\textbf{U}_{1}$, but this complexity is unnecessary to show here. All we need to know is that the next timestep is a function ${\\textbf{F}}$ of the present and past timesteps, the velocity, and the forcing term.\n",
    "\n",
    "$$\\textbf{U}_{2}=\\textbf{F}(\\textbf{U}_0, \\textbf{U}_1, \\textbf{V}, f_{1})$$\n",
    "\n",
    "> In geophysics we usually use a [Ricker Wavelet](https://wiki.seg.org/wiki/Dictionary:Ricker_wavelet) for the forcing term $f$, and usually inject that wavelet into one cell within the grid as time progresses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d9870e-642e-4357-a49a-bf220fd42d7c",
   "metadata": {},
   "source": [
    "### Kernel implementation\n",
    "\n",
    "In [kernels.c](kernels.c) is a kernel called **wave2d_4o** that implements the function **F**. OpenCL buffers store $\\textbf{U}_{0}, \\textbf{U}_{1}, \\textbf{U}_{2}$, and $\\textbf{V}$ on the compute device.\n",
    "\n",
    "```C++\n",
    "// Kernel to solve the wave equation with fourth-order accuracy in space\n",
    "__kernel void wave2d_4o (\n",
    "        __global float* U0,\n",
    "        __global float* U1,\n",
    "        __global float* U2,\n",
    "        __global float* V,\n",
    "        unsigned int N0,\n",
    "        unsigned int N1,\n",
    "        float dt2,\n",
    "        float inv_dx02,\n",
    "        float inv_dx12,\n",
    "        // Position, frequency, and time for the\n",
    "        // wavelet injection\n",
    "        unsigned int P0,\n",
    "        unsigned int P1,\n",
    "        float pi2fm2t2) {    \n",
    "\n",
    "    // U2, U1, U0, V is of size (N0, N1)\n",
    "    size_t i0=get_global_id(1); // Slowest dimension\n",
    "    size_t i1=get_global_id(0); // Fastest dimension\n",
    "    \n",
    "    // Required padding and coefficients for spatial finite difference\n",
    "    const int pad_l=2, pad_r=2, ncoeffs=5;\n",
    "    float coeffs[ncoeffs] = {-0.083333336f, 1.3333334f, -2.5f, 1.3333334f, -0.083333336f};\n",
    "    \n",
    "    // Limit i0 and i1 to the region of U2 within the padding\n",
    "    i0=min(i0, (size_t)(N0-1-pad_r));\n",
    "    i1=min(i1, (size_t)(N1-1-pad_r));\n",
    "    i0=max((size_t)pad_l, i0);\n",
    "    i1=max((size_t)pad_l, i1);\n",
    "    \n",
    "    // Position within the grid as a 1D offset\n",
    "    long offset=i0*N1+i1;\n",
    "    \n",
    "    // Temporary storage\n",
    "    float temp0=0.0f, temp1=0.0f;\n",
    "    float tempV=V[offset];\n",
    "    \n",
    "    // Calculate the Laplacian\n",
    "    #pragma unroll\n",
    "    for (long n=0; n<ncoeffs; n++) {\n",
    "        // Stride in dim0 is N1        \n",
    "        temp0+=coeffs[n]*U1[offset+(n*(long)N1)-(pad_l*(long)N1)];\n",
    "        // Stride in dim1 is 1\n",
    "        temp1+=coeffs[n]*U1[offset+n-pad_l];\n",
    "    }\n",
    "    \n",
    "    // Calculate the wavefield U2 at the next timestep\n",
    "    U2[offset]=(2.0f*U1[offset])-U0[offset]+((dt2*tempV*tempV)*(temp0*inv_dx02+temp1*inv_dx12));\n",
    "    \n",
    "    // Inject the forcing term at coordinates (P0, P1)\n",
    "    if ((i0==P0) && (i1==P1)) {\n",
    "        U2[offset]+=(1.0f-2.0f*pi2fm2t2)*exp(-pi2fm2t2);\n",
    "    }\n",
    "    \n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d266b76-ce52-455e-a9b5-c37b5238307c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Problem setup\n",
    "\n",
    "For this problem we create the 2D grid as a square box of size $(N0,N1)=(256,256)$. The velocity is uniform at 343m/s. This is approximately the speed of sound in air. Then we use a Ricker wavelet as a forcing term to 'let off a firework' in the middle of the box and run a number of timesteps to see how a sound wave propagates in the box. \n",
    "\n",
    "<figure style=\"margin-bottom 3em; margin-top: 2em; margin-left:auto; margin-right:auto; width:80%\">\n",
    "    <img style=\"vertical-align:middle\" src=\"../images/wave2d_problem.svg\"> <figcaption style= \"text-align:lower; margin:1em; float:bottom; vertical-align:bottom;\">Figure: Problem setup for the 2D wave equation.</figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcda1835-1595-438a-9d57-18f6839bc03c",
   "metadata": {},
   "source": [
    "At each timestep the kernel **wave2d_4o** is used to update the solution to the next timestep. Old wavefields that are no longer needed are recycled for efficiency.\n",
    "\n",
    "The code below writes the velocity array to disk, ready to be read in by the wave codes below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dcced67c-c103-4ec3-b21e-e83a00f313de",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import subprocess\n",
    "from ipywidgets import widgets\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import animation, rc\n",
    "from IPython.display import HTML\n",
    "\n",
    "sys.path.insert(0, os.path.abspath(\"../include\"))\n",
    "\n",
    "import py_helper\n",
    "\n",
    "float_type = np.float32\n",
    "\n",
    "defines=py_helper.load_defines(\"mat_size.hpp\")\n",
    "\n",
    "# Velocity of the medium\n",
    "vel=343.0\n",
    "\n",
    "# Make up the velocity and first two timesteps\n",
    "V=np.ones((defines[\"N0\"], defines[\"N1\"]), dtype=float_type)*vel\n",
    "\n",
    "# write files to disk\n",
    "V.tofile(\"array_V.dat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1637b9-c045-4b17-8492-a8a7c1f2f606",
   "metadata": {},
   "source": [
    "### Sequential (synchronous) IO solution\n",
    "\n",
    "In [wave2d_sync.cpp](wave2d_sync.cpp) we use an array of three OpenCL buffers to represent the wavefield at timesteps (0,1,2). A single command queue is used for both kernel execution and IO.\n",
    "\n",
    "<figure style=\"margin-bottom 3em; margin-top: 2em; margin-left:auto; margin-right:auto; width:100%\">\n",
    "    <img style=\"vertical-align:middle\" src=\"../images/sequential_io.svg\"> <figcaption style= \"text-align:lower; margin:1em; float:bottom; vertical-align:bottom;\">Figure: Sequential IO solution.</figcaption>\n",
    "</figure>\n",
    "\n",
    "#### Make and run the application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6e3ecc4-10ea-4f0c-8b9b-b62b61018e37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make: Nothing to be done for 'all'.\n"
     ]
    }
   ],
   "source": [
    "!make"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bac6b827-4ee7-4f24-9cbe-bc856bc18691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t               name: gfx1035 \n",
      "\t global memory size: 536 MB\n",
      "\t    max buffer size: 456 MB\n",
      "\t     max local size: (1024,1024,1024)\n",
      "\t     max work-items: 256\n",
      "dt=0.001166, Vmax=343.000000\n",
      "dt=0.00116618, fm=34.3, Vmax=343, dt2=1.35998e-06\n",
      "The synchronous calculation took 84009 milliseconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['/home/toby/Pelagos/Projects/OpenCL_Course/course_material/L9_IO_Optimisation/wave2d_sync.exe', '-gpu'], returncode=0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.run([os.path.join(os.getcwd(),\"wave2d_sync.exe\"), \"-gpu\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d690e0e-e7ab-4e33-a2aa-2988dfd62958",
   "metadata": {},
   "source": [
    "#### Application trace\n",
    "\n",
    "The script **make_traces.sh** produces traces in the **tau** folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c7d86a4-f911-4837-9917-2e4fcab10124",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t               name: gfx1035 \n",
      "\t global memory size: 536 MB\n",
      "\t    max buffer size: 456 MB\n",
      "\t     max local size: (1024,1024,1024)\n",
      "\t     max work-items: 256\n",
      "dt=0.001166, Vmax=343.000000\n",
      "dt=0.00116618, fm=34.3, Vmax=343, dt2=1.35998e-06\n",
      "device id: -2042467264.\n",
      "command id: 94555955408576.\n",
      "vendor id: 0.\n",
      "Got a bogus start! 2 .TAU application\n",
      "The synchronous calculation took 100352 milliseconds.\n",
      "/opt/tau/2.31.1/x86_64/bin/tau_merge -m tau.edf -e events.0.edf events.0.edf events.0.edf tautrace.0.0.0.trc tautrace.0.0.1.trc tautrace.0.0.2.trc tau.trc\n",
      "tautrace.0.0.0.trc: 18909 records read.\n",
      "tautrace.0.0.1.trc: 6 records read.\n",
      "tautrace.0.0.2.trc: 8326 records read.\n",
      "\t               name: gfx1035 \n",
      "\t global memory size: 536 MB\n",
      "\t    max buffer size: 456 MB\n",
      "\t     max local size: (1024,1024,1024)\n",
      "\t     max work-items: 256\n",
      "dt=0.001166, Vmax=343.000000\n",
      "dt=0.00116618, fm=34.3, Vmax=343, dt2=1.35998e-06\n",
      "device id: -315371040.\n",
      "command id: 94179739064784.\n",
      "vendor id: 0.\n",
      "Got a bogus start! 2 .TAU application\n",
      "device id: -315371040.\n",
      "command id: 94179725475520.\n",
      "vendor id: 0.\n",
      "Got a bogus start! 4 .TAU application\n",
      "device id: -315371040.\n",
      "command id: 94179726173600.\n",
      "vendor id: 0.\n",
      "Got a bogus start! 6 .TAU application\n",
      "device id: -315371040.\n",
      "command id: 94179739007072.\n",
      "vendor id: 0.\n",
      "Got a bogus start! 8 .TAU application\n",
      "device id: -315371040.\n",
      "command id: 94179738948576.\n",
      "vendor id: 0.\n",
      "Got a bogus start! 10 .TAU application\n",
      "device id: -315371040.\n",
      "command id: 94179738909952.\n",
      "vendor id: 0.\n",
      "Got a bogus start! 12 .TAU application\n",
      "The asynchronous calculation took 83262 milliseconds./opt/tau/2.31.1/x86_64/bin/tau_merge -m tau.edf -e events.0.edf events.0.edf events.0.edf events.0.edf events.0.edf events.0.edf events.0.edf events.0.edf events.0.edf events.0.edf events.0.edf events.0.edf events.0.edf tautrace.0.0.0.trc tautrace.0.0.1.trc tautrace.0.0.10.trc tautrace.0.0.11.trc tautrace.0.0.12.trc tautrace.0.0.2.trc tautrace.0.0.3.trc tautrace.0.0.4.trc tautrace.0.0.5.trc tautrace.0.0.6.trc tautrace.0.0.7.trc tautrace.0.0.8.trc tautrace.0.0.9.trc tau.trc\n",
      "tau.trc exists; override [y]? tautrace.0.0.0.trc: 20230 records read.\n",
      "tautrace.0.0.1.trc: 6 records read.\n",
      "tautrace.0.0.10.trc: 1414 records read.\n",
      "tautrace.0.0.11.trc: 6 records read.\n",
      "tautrace.0.0.12.trc: 1403 records read.\n",
      "tautrace.0.0.2.trc: 1286 records read.\n",
      "tautrace.0.0.3.trc: 6 records read.\n",
      "tautrace.0.0.4.trc: 1414 records read.\n",
      "tautrace.0.0.5.trc: 6 records read.\n",
      "tautrace.0.0.6.trc: 1414 records read.\n",
      "tautrace.0.0.7.trc: 6 records read.\n",
      "tautrace.0.0.8.trc: 1414 records read.\n",
      "tautrace.0.0.9.trc: 6 records read.\n"
     ]
    }
   ],
   "source": [
    "!./make_traces.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3fa9b9-e925-4899-9ef5-9490a04d5e14",
   "metadata": {},
   "source": [
    "Using google chrome type in the address [chrome://tracing](chrome://tracing) to open the tracing utility. If you load the file **tau/trace_sync.json** you should see something like this. The IO occurs after each kernel execution using the same command queue."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589fdcb5-31dd-4a66-b1a4-bef7e039546d",
   "metadata": {},
   "source": [
    "<figure style=\"margin-bottom 3em; margin-top: 2em; margin-left:auto; margin-right:auto; width:100%\">\n",
    "    <img style=\"vertical-align:middle\" src=\"../images/synchronous_io.png\"> <figcaption style= \"text-align:lower; margin:1em; float:bottom; vertical-align:bottom;\">Figure: Sequential IO solution.</figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c9d703-f3e4-4f1f-8434-3b24c32188ca",
   "metadata": {},
   "source": [
    "### Concurrent (asynchronous) IO solution\n",
    "\n",
    "In [wave2d_async.cpp](wave2d_async.cpp) is the solution for concurrent IO. The goal is to use **multiple command queues** so that while a  command queue is executing a kernel, the other is working on IO.\n",
    "\n",
    "<figure style=\"margin-bottom 3em; margin-top: 2em; margin-left:auto; margin-right:auto; width:100%\">\n",
    "    <img style=\"vertical-align:middle\" src=\"../images/concurrent_io.svg\"> <figcaption style= \"text-align:lower; margin:1em; float:bottom; vertical-align:bottom;\">Figure: Concurrent IO solution.</figcaption>\n",
    "</figure>\n",
    "\n",
    "#### Concurrent access to buffers is undefined\n",
    "\n",
    "In OpenCL it is **undefined behaviour** to read from a Buffer (using another command queue) at the same time as a kernel is using it. During construction of this module I found that reading from an OpenCL Buffer while it is being used by a kernel resulted in the instability of the solution or even a program crash. Therefore, we can safely read from Buffers when no kernel is using them. Our kernel needs access to wavefields at timesteps $\\textbf{U}_{0}, \\textbf{U}_{1}, \\textbf{U}_{2}$, therefore they are **not** safe to copy, but wavefields at earlier timesteps e.g $\\textbf{U}_{-2}, \\textbf{U}_{-1}$ **are** safe to copy.\n",
    "\n",
    "<figure style=\"margin-bottom 3em; margin-top: 2em; margin-left:auto; margin-right:auto; width:30%\">\n",
    "    <img style=\"vertical-align:middle\" src=\"../images/wavefields.svg\"> <figcaption style= \"text-align:lower; margin:1em; float:bottom; vertical-align:bottom;\">Figure: Wavefields that are ok to copy.</figcaption>\n",
    "</figure>\n",
    "\n",
    "#### Using Events to aid with concurrency\n",
    "\n",
    "The solution to enable concurrent IO is to have an array of at least four OpenCL buffers. We choose an array of **nscratch=5** buffers to allow extra time for copies to finish. Associated with the buffers is an array of five command queues for IO. Every queued OpenCL operation can depend on a list of OpenCL Events and produce one OpenCL event. Therefore we also create an array of five Events to make sure that IO waits for the kernel execution to finish. A separate compute queue is used just for the kernel. During each iteration **n** of the time loop then:\n",
    "\n",
    "1. Use **[clFinish](https://registry.khronos.org/OpenCL/sdk/3.0/docs/man/html/clFinish.html)** waits for all activity on command_queue[(n+2)%nscratch] to complete.\n",
    "1. Submit the kernel to solve for U[(n+2)%nscratch], place an event at Events[n%nscratch]\n",
    "1. Use the command_queue[(n-1)%nscratch] to copy the buffer at U[(n-1)%nscratch] back to host, depend on Events[(n-1)%nscratch] to make sure the kernel has finished.\n",
    "\n",
    "The following diagram shows how the dependencies play out with Events and command queues during a single iteration.\n",
    "\n",
    "<figure style=\"margin-bottom 3em; margin-top: 2em; margin-left:auto; margin-right:auto; width:30%\">\n",
    "    <img style=\"vertical-align:middle\" src=\"../images/wavefields_concurrent.svg\"> <figcaption style= \"text-align:lower; margin:1em; float:bottom; vertical-align:bottom;\">Figure: Compute and IO queues during an iteration.</figcaption>\n",
    "</figure>\n",
    "\n",
    "The code for the iterations is produced here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ce10d2-0688-4a30-892b-afff024c8eed",
   "metadata": {},
   "source": [
    "```C++\n",
    "    for (int n=0; n<NT; n++) {\n",
    "        \n",
    "        // Wait for the previous copy command to finish\n",
    "        h_errchk(\n",
    "            clFinish(command_queues[(n+2)%nscratch]),\n",
    "            \"Waiting for all previous things to finish\"\n",
    "        );\n",
    "        \n",
    "        // Get the wavefields\n",
    "        U0 = buffers_U[n%nscratch];\n",
    "        U1 = buffers_U[(n+1)%nscratch];\n",
    "        U2 = buffers_U[(n+2)%nscratch];\n",
    "        \n",
    "        // Shifted time\n",
    "        t = n*dt-2.0*td;\n",
    "        pi2fm2t2 = pi*pi*fm*fm*t*t;\n",
    "        \n",
    "        // Set kernel arguments\n",
    "        h_errchk(\n",
    "            clSetKernelArg(kernel, 0, sizeof(cl_mem), &U0 ),\n",
    "            \"setting kernel argument 0\"\n",
    "        );\n",
    "        h_errchk(\n",
    "            clSetKernelArg(kernel, 1, sizeof(cl_mem), &U1 ),\n",
    "            \"setting kernel argument 1\"\n",
    "        );\n",
    "        h_errchk(\n",
    "            clSetKernelArg(kernel, 2, sizeof(cl_mem), &U2 ),\n",
    "            \"setting kernel argument 2\"\n",
    "        );\n",
    "        h_errchk(\n",
    "            clSetKernelArg(kernel, 11, sizeof(cl_float), &pi2fm2t2 ),\n",
    "            \"setting kernel argument 11\"\n",
    "        );\n",
    "        \n",
    "        // Enqueue the wave solver    \n",
    "        h_errchk(\n",
    "            clEnqueueNDRangeKernel(\n",
    "                compute_queue,\n",
    "                kernel,\n",
    "                work_dim,\n",
    "                NULL,\n",
    "                global_size,\n",
    "                local_size,\n",
    "                0,\n",
    "                NULL,\n",
    "                &events[n%nscratch]), \n",
    "            \"Running the kernel\"\n",
    "        );\n",
    "          \n",
    "        // Read memory from the buffer to the host in an asynchronous manner\n",
    "        if (n>0) {\n",
    "            cl_int copy_index=n-1;\n",
    "            h_errchk(\n",
    "                clEnqueueReadBuffer(\n",
    "                    command_queues[copy_index%nscratch],\n",
    "                    buffers_U[copy_index%nscratch],\n",
    "                    blocking,\n",
    "                    0,\n",
    "                    nbytes_U,\n",
    "                    &array_out[copy_index*N0*N1],\n",
    "                    1,\n",
    "                    &events[copy_index%nscratch],\n",
    "                    NULL), \n",
    "                \"Asynchronous copy from U2 on device to host\"\n",
    "            );\n",
    "        }\n",
    "    }\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95733f27-00e3-492b-bea2-8bcbc0fe7881",
   "metadata": {},
   "source": [
    "#### Make and run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e741744b-3f79-4d55-8046-b829ce17d635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make: Nothing to be done for 'all'.\n"
     ]
    }
   ],
   "source": [
    "!make"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "582cea5a-05db-4afe-92ce-075a18bb95c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t               name: gfx1035 \n",
      "\t global memory size: 536 MB\n",
      "\t    max buffer size: 456 MB\n",
      "\t     max local size: (1024,1024,1024)\n",
      "\t     max work-items: 256\n",
      "dt=0.001166, Vmax=343.000000\n",
      "dt=0.00116618, fm=34.3, Vmax=343, dt2=1.35998e-06\n",
      "The asynchronous calculation took 54295 milliseconds."
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['/home/toby/Pelagos/Projects/OpenCL_Course/course_material/L9_IO_Optimisation/wave2d_async.exe', '-gpu'], returncode=0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run the application\n",
    "subprocess.run([os.path.join(os.getcwd(),\"wave2d_async.exe\"), \"-gpu\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae90139d-e944-414c-a3ab-f95c10dcf5cd",
   "metadata": {},
   "source": [
    "If we check the time elapsed we find that the concurrent IO solution took less time than the sequential IO solution. A trace of the OpenCL activity shows that IO is taking place during kernel execution.\n",
    "\n",
    "<figure style=\"margin-bottom 3em; margin-top: 2em; margin-left:auto; margin-right:auto; width:100%\">\n",
    "    <img style=\"vertical-align:middle\" src=\"../images/asynchronous_io.png\"> <figcaption style= \"text-align:lower; margin:1em; float:bottom; vertical-align:bottom;\">Figure: Concurrent IO solution.</figcaption>\n",
    "</figure>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e868c3-7c11-45bc-8b50-b8d5f8c803b1",
   "metadata": {},
   "source": [
    "### Plot the wavefield and explore results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "459cbfd2-0fdc-4492-9805-f76db5e9a6c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8403c800b64413d954b413eb910f4b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='n', max=639), Output()), _dom_classes=('widget-interact'â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Read the outputfile back in for display\n",
    "output=np.fromfile(\"array_out.dat\", dtype=float_type)\n",
    "nimages=int(output.size//(defines[\"N0\"]*defines[\"N1\"]))\n",
    "images=output.reshape(nimages, defines[\"N0\"], defines[\"N1\"])\n",
    "\n",
    "py_helper.plot_slices(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8f9bf8-b44f-4527-8ac3-3ea81fe9a8f3",
   "metadata": {},
   "source": [
    "## Summary of learnings\n",
    "\n",
    "In this module we explored how IO can take place at the same time as a kernel using multiple command queues. The concurrent IO solution was faster than the sequential IO solution. One does need to be careful that buffers are not being read or written at the same time as they are being used in a kernel, otherwise this leads to undefined behaviour. Events and the use of the **[clFinish](https://registry.khronos.org/OpenCL/sdk/3.0/docs/man/html/clFinish.html)** function can establish and enforce dependencies between activity that occurs across multiple command queues."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb824e5-856c-4b36-ac49-c3801294bc41",
   "metadata": {},
   "source": [
    "<address>\n",
    "Written by Dr. Toby Potter of <a href=\"https://www.pelagos-consulting.com\">Pelagos Consulting and Education</a> for the Pawsey Supercomputing Centre\n",
    "</address>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
